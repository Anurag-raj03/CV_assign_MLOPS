---

# ğŸ§ ğŸ“¸ Rock-Paper-Scissors: Real-Time MLOps Pipeline with OpenCV, Airflow & Transfer Learning

Welcome to the **Rock-Paper-Scissors (RPS) MLOps System** â€” a cutting-edge, production-ready MLOps pipeline designed to process, predict, retrain, and redeploy machine learning models in real time. This solution brings together best-in-class tools like **OpenCV**, **MobileNet**, **Airflow**, **DVC**, **S3**, **Docker**, **Streamlit**, **PostgreSQL**, **Prometheus**, **Grafana**, and **CI/CD via GitHub Actions & EC2**.

---

## ğŸš€ Key Features

* ğŸ§  **Transfer Learning** with MobileNet for accurate RPS image classification
* ğŸ¥ **Real-Time Inference** using OpenCV via live webcam
* ğŸ” **Auto-Retrain Trigger** when prediction count exceeds threshold using Airflow
* â˜ï¸ **DVC + S3** for robust **data versioning**
* ğŸ“¦ **MLflow** for **model versioning**, **metrics logging**, and **artifact tracking**
* ğŸ³ **Containerized Microservices** using Docker Compose
* ğŸ” **CI/CD** pipeline via GitHub Actions and EC2 integration
* ğŸ“Š **Prometheus + Grafana** for full-stack monitoring
* ğŸ—ƒï¸ **PostgreSQL** for storing labeled image metadata

---

## ğŸ“ Folder Structure & Purpose

```plaintext
.
â”œâ”€â”€ .dvc/                          # DVC configuration and cache for data tracking
â”œâ”€â”€ .github/workflows/            # CI/CD pipeline config (cicd.yml)
â”œâ”€â”€ airflow/                      # Airflow DAG for retraining logic
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ dvc_script.sh         # Script to push preprocessed data to S3 via DVC
â”œâ”€â”€ artifacts/                    # Saved models, metrics, and intermediate outputs
â”œâ”€â”€ Data/                         # Raw image data versioned via DVC
â”œâ”€â”€ Database_connection/          # PostgreSQL init and mock data scripts
â”œâ”€â”€ frontend/                     # Streamlit UI for uploading & predicting images
â”œâ”€â”€ inference/                    # Model inference and image classification code
â”œâ”€â”€ mlflow/                       # MLflow experiment setup
â”œâ”€â”€ monitoring/                   # Prometheus & Grafana config
â”œâ”€â”€ src/                          # Model training, preprocessing, logging
â”‚   â””â”€â”€ Dockerfile.src            # Dockerfile for training container
â”œâ”€â”€ utils/                        # Common functions (e.g., OpenCV, metrics)
â”œâ”€â”€ .env                          # Environment variables for AWS and DB
â”œâ”€â”€ docker-compose.yml           # Compose for local full-stack development
â”œâ”€â”€ docker-compose.build.yml     # Used by CI/CD to build and push Docker images
â”œâ”€â”€ docker-compose.deploy.yml    # Compose file used for EC2 deployment
â”œâ”€â”€ Dockerfile.backend           # FastAPI backend API Docker image
â”œâ”€â”€ main.py                       # Backend API entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
```

---

## ğŸ” System Workflow

```mermaid
flowchart TD
    A[User uploads image via Streamlit] --> B[Backend API receives image]
    B --> C[Model predicts class]
    C --> D[Prediction counter +1]
    D --> E{Threshold >= 3?}
    E -- No --> F[Wait for more inputs]
    E -- Yes --> G[Airflow DAG triggered]
    G --> H[Extract images from PostgreSQL]
    H --> I[Preprocess using OpenCV]
    I --> J[dvc_script.sh â†’ DVC Push to S3]
    J --> K[Retrain using MobileNet]
    K --> L[Log model to MLflow]
    L --> M[Save to artifacts/]
    M --> N[Restart backend with new model]
    N --> O[Serve updated predictions]
```

---

## ğŸ› ï¸ Airflow DAG - `rock_paper_scissors_retrain_pipeline`

**Trigger Condition**: Prediction count â‰¥ 3 (tracked in backend)
**Steps:**

1. ğŸ“¤ `extract_images_from_postgres`: Pulls labeled image data from PostgreSQL
2. ğŸ§¼ `preprocess_images`: Applies resizing, normalization, and augmentation
3. ğŸ§¾ `dvc_script.sh`:

   * Path: `airflow/scripts/dvc_script.sh`
   * Role: **Pushes preprocessed dataset to remote DVC storage (S3)** for version control
4. ğŸ¤– `retrain_rps_model`: Fine-tunes MobileNet, logs experiments to MLflow
5. ğŸ“¦ `MLflow Tracking`: Stores trained model, accuracy, loss, and other artifacts
6. ğŸ” Updated model is pulled and served by backend

---

## ğŸ³ Dockerized Microservices (Ports & Purpose)

| Service     | Port | Description                                |
| ----------- | ---- | ------------------------------------------ |
| PostgreSQL  | 5432 | Image label storage and metadata           |
| Airflow     | 8080 | DAG interface for retraining automation    |
| Backend API | 8000 | FastAPI for inference and DB communication |
| Streamlit   | 8501 | UI to upload images and get predictions    |
| Prometheus  | 9090 | Monitoring metrics collector               |
| Grafana     | 3000 | Visualization of metrics                   |
| MLflow      | 5000 | Model tracking interface                   |

ğŸš¨ **Note:** Only port `8501` (Streamlit frontend) is publicly exposed via EC2 for security.

---

## ğŸ“¦ DVC for **Data Versioning** Only

* **Remote Storage:** `s3://anurag-dvc-eu-data`
* **Tracked Items:**

  * ğŸ“‚ Raw and preprocessed image data
  * ğŸ“ Cleaned image-label metadata
  * ğŸ“ˆ Training inputs for reproducibility

ğŸ§¾ `airflow/scripts/dvc_script.sh` automates this process after preprocessing:

```bash
#!/bin/bash
dvc add Data/processed/
dvc push
```

---

## ğŸ“˜ MLflow for **Model Versioning** & Experiment Tracking

* Logs:

  * ğŸ§  Model version & weights
  * ğŸ“‰ Accuracy, loss, precision, recall
  * ğŸ“ Artifacts (model.pkl, training logs, plots)
* Access via: `http://localhost:5000`
* Full experiment reproducibility

---

## ğŸ“ˆ Prometheus + Grafana Monitoring

ğŸ“Š Visualized metrics:

* Request duration
* Prediction latency
* Model version in use
* CPU/Memory usage
* Endpoint hits (`/predict`, `/metrics`, `/upload`)

---

## ğŸ” CI/CD with GitHub Actions & EC2

* **Trigger:** Push to `main` branch
* **Pipeline Includes:**

  * âœ… Set up Python, DVC, Docker
  * ğŸ“¦ Pull dataset from S3 (via DVC)
  * ğŸ³ Build and push Docker images to DockerHub
  * ğŸ“¤ Deploy updated stack to EC2 using SSH + Docker Compose

---

## ğŸ§± Production-Ready MLOps Architecture

This system follows **best practices in modern MLOps**, with:

| MLOps Phase        | Tool/Service Used                 |
| ------------------ | --------------------------------- |
| Inference          | OpenCV + FastAPI + Streamlit      |
| Monitoring         | Prometheus + Grafana              |
| Data Versioning    | DVC + S3                          |
| Model Versioning   | MLflow                            |
| Orchestration      | Airflow                           |
| Experiment Logging | MLflow                            |
| Continuous Deploy  | GitHub Actions + EC2 + Docker     |
| Microservices      | Docker Compose                    |
| CI/CD Secrets      | `.env` + GitHub Secrets + EC2 SSH |

---

## ğŸ§± Component & Interaction Overview

```mermaid
flowchart TD
    subgraph UserInteraction
        A[ğŸ“¸ Streamlit UI] --> B[ğŸš€ Backend API (FastAPI)]
        B --> C[ğŸ§  Model Prediction]
        B --> Counter[ğŸ“Š Prediction Counter]
        Counter -->|>= 3| Airflow[ğŸ› ï¸ Airflow DAG Triggered]
    end

    subgraph AirflowPipeline
        Data[ğŸ“‚ Data Folder] --> Airflow[ğŸ“¡ Airflow DAG]
        Airflow --> Step1[ğŸ“¤ Extract from PostgreSQL]
        Step1 --> Step2[ğŸ§¼ Preprocess Images]
        Step2 --> DVC_Script[ğŸ“¦ Run dvc_script.sh â†’ Push to S3 via DVC]
        DVC_Script --> DVC[S3 Bucket (via DVC)]
        Step2 --> Step3[ğŸ¤– Retrain MobileNet Model]
        Step3 --> MLflow[ğŸ§¾ Log to MLflow (metrics + artifacts)]
        Step3 --> Artifacts[ğŸ“ Save model to artifacts/]
    end

    subgraph Training
        Data --> src[âš™ï¸ Training Scripts (src/)]
        src --> Artifacts
        Artifacts --> Backend[â™»ï¸ Backend Reloads Updated Model]
    end
```


---

## ğŸ‘¨â€ğŸ’» Connect With Me

* ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/anurag-raj-770b6524a/)
* ğŸ§  [Kaggle](https://www.kaggle.com/anuragraj03)
* ğŸ™ [GitHub](https://github.com/Anurag-raj03)
* ğŸ³ [DockerHub](https://hub.docker.com/u/anuragraj03)
* ğŸ“§ [anuragraj4483@gmail.com](mailto:anuragraj4483@gmail.com)

---

## ğŸ“Œ Summary

> This project demonstrates a **scalable, production-grade MLOps pipeline** by integrating the **complete lifecycle of a deep learning model**, including:

âœ… Real-time prediction
âœ… Automated data and model versioning
âœ… Scheduled and conditional retraining
âœ… Dockerized, modular architecture
âœ… Full observability via Prometheus + Grafana
âœ… Reliable CI/CD with minimal human intervention
âœ… Streamlit-based UI with FastAPI-powered backend

âš™ï¸ *Itâ€™s not just a project â€” itâ€™s a blueprint for building real-world, deployable MLOps systems.*


